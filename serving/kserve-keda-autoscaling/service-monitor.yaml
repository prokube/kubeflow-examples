# PodMonitor to scrape vLLM metrics from KServe InferenceService
# This enables Prometheus to collect the metrics used by KEDA for autoscaling
#
# Prerequisites:
# - Prometheus Operator installed (kube-prometheus-stack)
# - vLLM runtime exposes metrics at /metrics endpoint
#
apiVersion: monitoring.coreos.com/v1
kind: PodMonitor
metadata:
  name: opt-125m-vllm-metrics
  labels:
    app: opt-125m-vllm
    # Label to match Prometheus Operator's podMonitorSelector
    release: kube-prometheus-stack
spec:
  selector:
    matchLabels:
      serving.kserve.io/inferenceservice: opt-125m-vllm
  namespaceSelector:
    matchNames:
      - <your-namespace>  # TODO: Replace with your namespace
  podMetricsEndpoints:
    - port: user-port
      path: /metrics
      interval: 15s
      scrapeTimeout: 10s
